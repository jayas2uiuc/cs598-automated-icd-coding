{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d011a9ae",
      "metadata": {
        "id": "d011a9ae"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7054bd2",
      "metadata": {
        "id": "d7054bd2"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import itertools\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fb5ade7",
      "metadata": {
        "id": "6fb5ade7"
      },
      "outputs": [],
      "source": [
        "def removePunctuations(text):\n",
        "    remove = string.punctuation.replace(\"'\", \"\") \n",
        "    pattern = r\"[{}]\".format(remove) \n",
        "    return re.sub(pattern, \" \", text) \n",
        "\n",
        "def replaceDigitsWithd(text):\n",
        "    return re.sub('\\d', 'd', text)\n",
        "\n",
        "def preprocessText(text):\n",
        "    text = text.lower()\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    text = removePunctuations(text)\n",
        "#     text = TextBlob(text).correct()\n",
        "    text = replaceDigitsWithd(text)\n",
        "    output = text.split(' ')\n",
        "    output = list(filter(lambda a: a != '', output))\n",
        "    return output\n",
        "\n",
        "def getWordCounts(data):\n",
        "    combinedList = list(itertools.chain.from_iterable(data))\n",
        "    countDict = dict(Counter(combinedList))\n",
        "    return countDict\n",
        "\n",
        "def findCorrectSpelling(inputWord, countDict, minFreq):  \n",
        "    minDistance = 1e10\n",
        "    correctSpelling = inputWord\n",
        "    for word in countDict.keys():        \n",
        "        if inputWord != word:\n",
        "            distance = nltk.edit_distance(word, inputWord)\n",
        "            if distance < minDistance:\n",
        "                minDistance = distance\n",
        "                correctSpelling = word\n",
        "    return correctSpelling\n",
        "\n",
        "def getSpellingCorrections(countDict, minFreq = 5):\n",
        "    corrections = {}\n",
        "    words = countDict.keys()\n",
        "    for word in words:\n",
        "        if countDict[word] < minFreq:\n",
        "            corrections[word] = findCorrectSpelling(word, countDict, minFreq)\n",
        "    return corrections"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mam5if6oGroC",
        "outputId": "971f7735-6d30-48bf-8196-0c827b8d3a0d"
      },
      "id": "mam5if6oGroC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d31cb5fd",
      "metadata": {
        "id": "d31cb5fd"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_pickle('/content/drive/MyDrive/MIMIC/cleanData-4000.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_max_len = 2200\n",
        "dataset = dataset[dataset['PREPROCESSED_TEXT'].map(len) < drop_max_len]"
      ],
      "metadata": {
        "id": "5cuEhbOYKUmI"
      },
      "id": "5cuEhbOYKUmI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80af365b",
      "metadata": {
        "id": "80af365b"
      },
      "outputs": [],
      "source": [
        "from ast import literal_eval\n",
        "dataset['ICD9_CODE'] = dataset.ICD9_CODE.apply(lambda x: literal_eval(str(x)))\n",
        "\n",
        "uniqCodes = set(itertools.chain.from_iterable(dataset['ICD9_CODE']))\n",
        "code2idx = {code: idx for idx, code in enumerate(uniqCodes)}\n",
        "\n",
        "dataset['Y'] = dataset['ICD9_CODE'].apply(lambda codeList: [code2idx[code] for code in codeList])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7939ae9b",
      "metadata": {
        "id": "7939ae9b"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "dataset['Z'] = list(mlb.fit_transform(dataset.Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "829a7b67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "829a7b67",
        "outputId": "84b892e0-58c1-4806-f0b1-a3fdc3f0a9e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Nursing/other        1245\n",
              "Radiology            1224\n",
              "ECG                   536\n",
              "Nursing               414\n",
              "Physician             234\n",
              "Discharge summary     130\n",
              "Echo                   95\n",
              "Respiratory            30\n",
              "General                15\n",
              "Rehab Services         13\n",
              "Nutrition              10\n",
              "Social Work             2\n",
              "Case Management         1\n",
              "Name: CATEGORY, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "dataset['CATEGORY'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uniqueCats = set(dataset['CATEGORY'])"
      ],
      "metadata": {
        "id": "G7kfr7NLLbCt"
      },
      "id": "G7kfr7NLLbCt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fe63e56",
      "metadata": {
        "id": "5fe63e56"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "dataset['CATOHE'] = list(ohe.fit_transform(dataset['CATEGORY'].values.reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c6abb15",
      "metadata": {
        "id": "5c6abb15"
      },
      "outputs": [],
      "source": [
        "num_records = len(dataset)\n",
        "trainDf = dataset.iloc[:int(0.8*num_records)]\n",
        "valDf = dataset.iloc[int(0.8*num_records):int(0.9*num_records)]\n",
        "testDf = dataset.iloc[int(0.9*num_records):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "989cdd15",
      "metadata": {
        "id": "989cdd15"
      },
      "outputs": [],
      "source": [
        "tokenFreq = Counter(itertools.chain.from_iterable(dataset['PREPROCESSED_TEXT']))\n",
        "\n",
        "tokenFreqTrain = Counter(itertools.chain.from_iterable(trainDf['PREPROCESSED_TEXT']))\n",
        "word2idxTrain = {k: i+1 for i, k in enumerate(tokenFreqTrain.keys())}\n",
        "word2idxTrain['unk'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b552b114",
      "metadata": {
        "id": "b552b114"
      },
      "outputs": [],
      "source": [
        "trainDf['X'] = trainDf['PREPROCESSED_TEXT'].apply(lambda words: [word2idxTrain[word] if word in word2idxTrain else 0 for word in words])\n",
        "valDf['X'] = valDf['PREPROCESSED_TEXT'].apply(lambda words: [word2idxTrain[word] if word in word2idxTrain else 0 for word in words])\n",
        "testDf['X'] = testDf['PREPROCESSED_TEXT'].apply(lambda words: [word2idxTrain[word] if word in word2idxTrain else 0 for word in words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c15fb16",
      "metadata": {
        "id": "0c15fb16"
      },
      "outputs": [],
      "source": [
        "dataset['REPORT_LENGTH'] = dataset.PREPROCESSED_TEXT.apply(lambda p: len(p))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10ce2284",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "10ce2284",
        "outputId": "34097d1f-0281-4578-c2e8-413b79cd7568"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2675.,  736.,  210.,  103.,   54.,   44.,   37.,   39.,   27.,\n",
              "          24.]),\n",
              " array([   3. ,  221.2,  439.4,  657.6,  875.8, 1094. , 1312.2, 1530.4,\n",
              "        1748.6, 1966.8, 2185. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.hist(dataset.REPORT_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7e860f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7e860f4",
        "outputId": "79db5691-5a7f-43c9-b46e-7b21394a87e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2185"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "max_report_len = np.max(dataset['REPORT_LENGTH'])\n",
        "max_report_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d52961ed",
      "metadata": {
        "id": "d52961ed"
      },
      "outputs": [],
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        super().__init__()\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.dataframe.iloc[index]\n",
        "        return torch.tensor(row.X), row.CATOHE, row.Z\n",
        "    \n",
        "def my_collate(data):    \n",
        "    Xs, Cats, Ys = zip(*data)    \n",
        "    maxSize = max_report_len\n",
        "    bz = len(Xs)\n",
        "    \n",
        "    y = torch.tensor(Ys, dtype=torch.float)\n",
        "    cat = torch.tensor(Cats, dtype=torch.float)\n",
        "    x = torch.zeros((bz, maxSize), dtype=torch.int)\n",
        "    mask = torch.zeros((bz, maxSize), dtype=torch.bool)\n",
        "    \n",
        "    for i, X in enumerate(Xs):\n",
        "        for j, wordIdx in enumerate(X):\n",
        "            x[i][j] = wordIdx\n",
        "            mask[i][j] = True\n",
        "    \n",
        "    return x, mask, cat, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e0f47e3",
      "metadata": {
        "id": "3e0f47e3"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):    \n",
        "    def __init__(self, num_words, out_classes, numCats, category_layers=-1, hidden_sizes=None ):\n",
        "        super().__init__()\n",
        "        self.category_layers = category_layers\n",
        "        self.embedding = nn.Embedding(num_embeddings=num_words, embedding_dim=300)\n",
        "        prev_size = 300\n",
        "        self.fc_layers = nn.ModuleList()\n",
        "        if category_layers > -1:\n",
        "            prev_size += numCats\n",
        "        if category_layers > 0:\n",
        "            for hsize in hidden_sizes:\n",
        "                self.fc_layers.append(nn.Linear(prev_size, hsize))\n",
        "                self.fc_layers.append(nn.Sigmoid())\n",
        "                prev_size = hsize\n",
        "        self.fc_final = nn.Linear(in_features=prev_size, out_features=out_classes)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x, mask, cat):\n",
        "        try:\n",
        "          x = self.embedding(x)\n",
        "        except:\n",
        "          print(torch.max(x))\n",
        "          raise Exception('I know Python!')\n",
        "\n",
        "        maskUnsq = mask.unsqueeze(-1)\n",
        "        x = torch.sum(x*maskUnsq, dim=1)\n",
        "        x = x/torch.sum(maskUnsq, dim=1)\n",
        "        if(self.category_layers != -1):\n",
        "            x = torch.cat((cat, x), dim=-1)\n",
        "        if(self.category_layers > 0):\n",
        "            for fc_layer in self.fc_layers:\n",
        "                x = fc_layer(x)\n",
        "        x = self.fc_final(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18f6b5b6",
      "metadata": {
        "id": "18f6b5b6"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, n_epochs, optimizer):\n",
        "    the_last_val_loss = 1000\n",
        "    patience = 4\n",
        "    trigger_times = 0\n",
        "    min_delta = 0.0001\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        iterations = 0\n",
        "        model = model.cuda()\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for x, mask, cat, y in train_loader: \n",
        "            x = x.cuda()\n",
        "            mask = mask.cuda()           \n",
        "            cat = cat.cuda()\n",
        "            y = y.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(x, mask, cat)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            if iterations%10 == 0:             \n",
        "              print('Iteration: {} \\t Training Loss: {:.6f}'.format(iterations+1, train_loss/(iterations+1)))\n",
        "            iterations += 1\n",
        "\n",
        "        train_loss = train_loss / len(train_loader)\n",
        "        print('*--------*')\n",
        "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
        "        val_loss, p, r, f = eval_model(model, val_loader)\n",
        "        print('Epoch: {} \\t Validation loss: {:.2f}, p: {:.2f}, r: {:.2f}, f1: {:.2f}'\n",
        "              .format(epoch+1, val_loss, p, r, f))\n",
        "        \n",
        "        # Early stopping\n",
        "        if val_loss > the_last_val_loss or (the_last_val_loss-val_loss)<min_delta:\n",
        "            trigger_times += 1\n",
        "            print('trigger times:', trigger_times)\n",
        "\n",
        "            if trigger_times >= patience:\n",
        "                print('Early stopping!\\nStart to test process.')\n",
        "                return model\n",
        "        else:\n",
        "            print('trigger times: 0')\n",
        "            trigger_times = 0\n",
        "\n",
        "        the_last_val_loss = val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f11eb6c0",
      "metadata": {
        "id": "f11eb6c0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
        "def eval_model(model, val_loader):\n",
        "    model = model.cuda()    \n",
        "    model.eval()\n",
        "    y_pred = torch.LongTensor()\n",
        "    y_score = torch.Tensor()\n",
        "    y_true = torch.LongTensor()\n",
        "    val_loss = 0\n",
        "    for x, mask, cat, y in val_loader:\n",
        "        x = x.cuda()\n",
        "        mask = mask.cuda()           \n",
        "        cat = cat.cuda()\n",
        "        y = y.cuda()\n",
        "        y_hat = model(x, mask, cat)\n",
        "        loss = criterion(y_hat, y)\n",
        "        y_score = torch.cat((y_score,  y_hat.detach().to('cpu')), dim=0)\n",
        "        y_hat = (y_hat > 0.5).int()\n",
        "        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
        "        y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n",
        "        val_loss += loss.item()\n",
        "    val_loss = val_loss / len(val_loader)\n",
        "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average='samples')\n",
        "    return val_loss, p, r, f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d596934d",
      "metadata": {
        "id": "d596934d"
      },
      "outputs": [],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(MyDataset(trainDf), batch_size=64, shuffle=True, collate_fn = my_collate, num_workers=8)\n",
        "val_dataloader = torch.utils.data.DataLoader(MyDataset(valDf), batch_size=64, shuffle=True, collate_fn = my_collate, num_workers=8)\n",
        "test_dataloader = torch.utils.data.DataLoader(MyDataset(testDf), batch_size=64, shuffle=True, collate_fn = my_collate, num_workers=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bbbcba7",
      "metadata": {
        "id": "5bbbcba7"
      },
      "outputs": [],
      "source": [
        "vocabSize = len(word2idxTrain)\n",
        "numCodes = len(uniqCodes)\n",
        "nEpochs = 15\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1650b2d0",
      "metadata": {
        "id": "1650b2d0"
      },
      "source": [
        "### BOT Baseline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c329115",
      "metadata": {
        "id": "1c329115"
      },
      "outputs": [],
      "source": [
        "model_cat_m1 = Model(vocabSize+1, numCodes, len(uniqueCats))\n",
        "optimizer_cat_m1 = torch.optim.Adam(model_cat_m1.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a5bdd0",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9a5bdd0",
        "outputId": "4add2f7e-5a95-432b-ffdb-8d6db017a6cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1 \t Training Loss: 0.694348\n",
            "Iteration: 11 \t Training Loss: 0.652414\n",
            "Iteration: 21 \t Training Loss: 0.607637\n",
            "Iteration: 31 \t Training Loss: 0.562363\n",
            "Iteration: 41 \t Training Loss: 0.519418\n",
            "Iteration: 51 \t Training Loss: 0.476403\n",
            "Iteration: 61 \t Training Loss: 0.437020\n",
            "Iteration: 71 \t Training Loss: 0.402326\n",
            "Iteration: 81 \t Training Loss: 0.372457\n",
            "Iteration: 91 \t Training Loss: 0.346694\n",
            "*--------*\n",
            "Epoch: 1 \t Training Loss: 0.328800\n",
            "Epoch: 1 \t Validation loss: 0.11, p: 0.76, r: 0.09, f1: 0.15\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.131687\n",
            "Iteration: 11 \t Training Loss: 0.119270\n",
            "Iteration: 21 \t Training Loss: 0.114613\n",
            "Iteration: 31 \t Training Loss: 0.111742\n",
            "Iteration: 41 \t Training Loss: 0.108760\n",
            "Iteration: 51 \t Training Loss: 0.107732\n",
            "Iteration: 61 \t Training Loss: 0.105626\n",
            "Iteration: 71 \t Training Loss: 0.104819\n",
            "Iteration: 81 \t Training Loss: 0.103719\n",
            "Iteration: 91 \t Training Loss: 0.102705\n",
            "*--------*\n",
            "Epoch: 2 \t Training Loss: 0.102226\n",
            "Epoch: 2 \t Validation loss: 0.09, p: 0.83, r: 0.08, f1: 0.14\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.087333\n",
            "Iteration: 11 \t Training Loss: 0.095207\n",
            "Iteration: 21 \t Training Loss: 0.094297\n",
            "Iteration: 31 \t Training Loss: 0.093072\n",
            "Iteration: 41 \t Training Loss: 0.093437\n",
            "Iteration: 51 \t Training Loss: 0.093211\n",
            "Iteration: 61 \t Training Loss: 0.092966\n",
            "Iteration: 71 \t Training Loss: 0.092628\n",
            "Iteration: 81 \t Training Loss: 0.092295\n",
            "Iteration: 91 \t Training Loss: 0.092250\n",
            "*--------*\n",
            "Epoch: 3 \t Training Loss: 0.092270\n",
            "Epoch: 3 \t Validation loss: 0.09, p: 0.72, r: 0.10, f1: 0.18\n",
            "trigger times: 1\n",
            "Iteration: 1 \t Training Loss: 0.100226\n",
            "Iteration: 11 \t Training Loss: 0.090476\n",
            "Iteration: 21 \t Training Loss: 0.089248\n",
            "Iteration: 31 \t Training Loss: 0.089768\n",
            "Iteration: 41 \t Training Loss: 0.089709\n",
            "Iteration: 51 \t Training Loss: 0.089217\n",
            "Iteration: 61 \t Training Loss: 0.089416\n",
            "Iteration: 71 \t Training Loss: 0.089606\n",
            "Iteration: 81 \t Training Loss: 0.089572\n",
            "Iteration: 91 \t Training Loss: 0.089666\n",
            "*--------*\n",
            "Epoch: 4 \t Training Loss: 0.089541\n",
            "Epoch: 4 \t Validation loss: 0.09, p: 0.82, r: 0.08, f1: 0.14\n",
            "trigger times: 2\n",
            "Iteration: 1 \t Training Loss: 0.080932\n",
            "Iteration: 11 \t Training Loss: 0.088882\n",
            "Iteration: 21 \t Training Loss: 0.087987\n",
            "Iteration: 31 \t Training Loss: 0.087143\n",
            "Iteration: 41 \t Training Loss: 0.087688\n",
            "Iteration: 51 \t Training Loss: 0.087912\n",
            "Iteration: 61 \t Training Loss: 0.087624\n",
            "Iteration: 71 \t Training Loss: 0.087708\n",
            "Iteration: 81 \t Training Loss: 0.087800\n",
            "Iteration: 91 \t Training Loss: 0.087659\n",
            "*--------*\n",
            "Epoch: 5 \t Training Loss: 0.087577\n",
            "Epoch: 5 \t Validation loss: 0.09, p: 0.79, r: 0.09, f1: 0.16\n",
            "trigger times: 3\n",
            "Iteration: 1 \t Training Loss: 0.093024\n",
            "Iteration: 11 \t Training Loss: 0.085602\n",
            "Iteration: 21 \t Training Loss: 0.086834\n",
            "Iteration: 31 \t Training Loss: 0.086388\n",
            "Iteration: 41 \t Training Loss: 0.086294\n",
            "Iteration: 51 \t Training Loss: 0.086606\n",
            "Iteration: 61 \t Training Loss: 0.085983\n",
            "Iteration: 71 \t Training Loss: 0.086096\n",
            "Iteration: 81 \t Training Loss: 0.086247\n",
            "Iteration: 91 \t Training Loss: 0.085909\n",
            "*--------*\n",
            "Epoch: 6 \t Training Loss: 0.085788\n",
            "Epoch: 6 \t Validation loss: 0.09, p: 0.73, r: 0.10, f1: 0.17\n",
            "trigger times: 4\n",
            "Early stopping!\n",
            "Start to test process.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (embedding): Embedding(10932, 300)\n",
              "  (fc_layers): ModuleList()\n",
              "  (fc_final): Linear(in_features=300, out_features=649, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "train(model_cat_m1, train_dataloader, val_dataloader, nEpochs, optimizer_cat_m1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ec02ead",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ec02ead",
        "outputId": "24d14d3d-e0b2-4ad1-b507-f0f8b8394614"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.09427695559172691,\n",
              " 0.6579746835443038,\n",
              " 0.0810764249640881,\n",
              " 0.14126848654160634)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "eval_model(model_cat_m1, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07ee121f",
      "metadata": {
        "id": "07ee121f"
      },
      "source": [
        "### BOT Baseline w/ Cat 0 Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e55ae9",
      "metadata": {
        "id": "53e55ae9"
      },
      "outputs": [],
      "source": [
        "model_cat_0 = Model(vocabSize+1, numCodes, len(uniqueCats), category_layers=0)\n",
        "optimizer_cat_0 = torch.optim.Adam(model_cat_0.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaf91393",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaf91393",
        "outputId": "284b9020-55ab-46b0-c698-5b32828d9c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1 \t Training Loss: 0.694384\n",
            "Iteration: 11 \t Training Loss: 0.690100\n",
            "Iteration: 21 \t Training Loss: 0.685443\n",
            "Iteration: 31 \t Training Loss: 0.681042\n",
            "Iteration: 41 \t Training Loss: 0.676279\n",
            "Iteration: 51 \t Training Loss: 0.671620\n",
            "Iteration: 61 \t Training Loss: 0.666686\n",
            "Iteration: 71 \t Training Loss: 0.661970\n",
            "Iteration: 81 \t Training Loss: 0.657114\n",
            "Iteration: 91 \t Training Loss: 0.652179\n",
            "*--------*\n",
            "Epoch: 1 \t Training Loss: 0.648351\n",
            "Epoch: 1 \t Validation loss: 0.60, p: 0.35, r: 0.12, f1: 0.15\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.602780\n",
            "Iteration: 11 \t Training Loss: 0.594628\n",
            "Iteration: 21 \t Training Loss: 0.589145\n",
            "Iteration: 31 \t Training Loss: 0.584318\n",
            "Iteration: 41 \t Training Loss: 0.578791\n",
            "Iteration: 51 \t Training Loss: 0.573265\n",
            "Iteration: 61 \t Training Loss: 0.567345\n",
            "Iteration: 71 \t Training Loss: 0.561904\n",
            "Iteration: 81 \t Training Loss: 0.556913\n",
            "Iteration: 91 \t Training Loss: 0.552097\n",
            "*--------*\n",
            "Epoch: 2 \t Training Loss: 0.547851\n",
            "Epoch: 2 \t Validation loss: 0.49, p: 0.81, r: 0.07, f1: 0.13\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.491632\n",
            "Iteration: 11 \t Training Loss: 0.486949\n",
            "Iteration: 21 \t Training Loss: 0.483781\n",
            "Iteration: 31 \t Training Loss: 0.478753\n",
            "Iteration: 41 \t Training Loss: 0.473786\n",
            "Iteration: 51 \t Training Loss: 0.468362\n",
            "Iteration: 61 \t Training Loss: 0.462856\n",
            "Iteration: 71 \t Training Loss: 0.457884\n",
            "Iteration: 81 \t Training Loss: 0.452583\n",
            "Iteration: 91 \t Training Loss: 0.447944\n",
            "*--------*\n",
            "Epoch: 3 \t Training Loss: 0.444010\n",
            "Epoch: 3 \t Validation loss: 0.39, p: 0.83, r: 0.07, f1: 0.12\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.397657\n",
            "Iteration: 11 \t Training Loss: 0.387805\n",
            "Iteration: 21 \t Training Loss: 0.382826\n",
            "Iteration: 31 \t Training Loss: 0.378670\n",
            "Iteration: 41 \t Training Loss: 0.375162\n",
            "Iteration: 51 \t Training Loss: 0.370856\n",
            "Iteration: 61 \t Training Loss: 0.365597\n",
            "Iteration: 71 \t Training Loss: 0.361911\n",
            "Iteration: 81 \t Training Loss: 0.357172\n",
            "Iteration: 91 \t Training Loss: 0.353025\n",
            "*--------*\n",
            "Epoch: 4 \t Training Loss: 0.350146\n",
            "Epoch: 4 \t Validation loss: 0.31, p: 0.83, r: 0.06, f1: 0.12\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.320250\n",
            "Iteration: 11 \t Training Loss: 0.309058\n",
            "Iteration: 21 \t Training Loss: 0.303441\n",
            "Iteration: 31 \t Training Loss: 0.299127\n",
            "Iteration: 41 \t Training Loss: 0.293639\n",
            "Iteration: 51 \t Training Loss: 0.290307\n",
            "Iteration: 61 \t Training Loss: 0.286893\n",
            "Iteration: 71 \t Training Loss: 0.283259\n",
            "Iteration: 81 \t Training Loss: 0.280405\n",
            "Iteration: 91 \t Training Loss: 0.277597\n",
            "*--------*\n",
            "Epoch: 5 \t Training Loss: 0.275008\n",
            "Epoch: 5 \t Validation loss: 0.24, p: 0.80, r: 0.06, f1: 0.12\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.241420\n",
            "Iteration: 11 \t Training Loss: 0.242247\n",
            "Iteration: 21 \t Training Loss: 0.239541\n",
            "Iteration: 31 \t Training Loss: 0.236545\n",
            "Iteration: 41 \t Training Loss: 0.233005\n",
            "Iteration: 51 \t Training Loss: 0.231004\n",
            "Iteration: 61 \t Training Loss: 0.228966\n",
            "Iteration: 71 \t Training Loss: 0.226275\n",
            "Iteration: 81 \t Training Loss: 0.224108\n",
            "Iteration: 91 \t Training Loss: 0.221529\n",
            "*--------*\n",
            "Epoch: 6 \t Training Loss: 0.219997\n",
            "Epoch: 6 \t Validation loss: 0.20, p: 0.80, r: 0.06, f1: 0.12\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.217725\n",
            "Iteration: 11 \t Training Loss: 0.196059\n",
            "Iteration: 21 \t Training Loss: 0.196418\n",
            "Iteration: 31 \t Training Loss: 0.192910\n",
            "Iteration: 41 \t Training Loss: 0.190657\n",
            "Iteration: 51 \t Training Loss: 0.189311\n",
            "Iteration: 61 \t Training Loss: 0.186898\n",
            "Iteration: 71 \t Training Loss: 0.185499\n",
            "Iteration: 81 \t Training Loss: 0.184041\n",
            "Iteration: 91 \t Training Loss: 0.182791\n",
            "*--------*\n",
            "Epoch: 7 \t Training Loss: 0.181636\n",
            "Epoch: 7 \t Validation loss: 0.16, p: 0.78, r: 0.07, f1: 0.12\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.161383\n",
            "Iteration: 11 \t Training Loss: 0.165171\n",
            "Iteration: 21 \t Training Loss: 0.163710\n",
            "Iteration: 31 \t Training Loss: 0.162757\n",
            "Iteration: 41 \t Training Loss: 0.161557\n",
            "Iteration: 51 \t Training Loss: 0.160949\n",
            "Iteration: 61 \t Training Loss: 0.159792\n",
            "Iteration: 71 \t Training Loss: 0.158106\n",
            "Iteration: 81 \t Training Loss: 0.157375\n",
            "Iteration: 91 \t Training Loss: 0.156418\n",
            "*--------*\n",
            "Epoch: 8 \t Training Loss: 0.155450\n",
            "Epoch: 8 \t Validation loss: 0.14, p: 0.77, r: 0.07, f1: 0.13\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.136597\n",
            "Iteration: 11 \t Training Loss: 0.146281\n",
            "Iteration: 21 \t Training Loss: 0.143908\n",
            "Iteration: 31 \t Training Loss: 0.143220\n",
            "Iteration: 41 \t Training Loss: 0.142120\n",
            "Iteration: 51 \t Training Loss: 0.141770\n",
            "Iteration: 61 \t Training Loss: 0.140704\n",
            "Iteration: 71 \t Training Loss: 0.139732\n",
            "Iteration: 81 \t Training Loss: 0.139008\n",
            "Iteration: 91 \t Training Loss: 0.138282\n",
            "*--------*\n",
            "Epoch: 9 \t Training Loss: 0.137644\n",
            "Epoch: 9 \t Validation loss: 0.13, p: 0.77, r: 0.07, f1: 0.13\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.136284\n",
            "Iteration: 11 \t Training Loss: 0.130851\n",
            "Iteration: 21 \t Training Loss: 0.129459\n",
            "Iteration: 31 \t Training Loss: 0.127706\n",
            "Iteration: 41 \t Training Loss: 0.128642\n",
            "Iteration: 51 \t Training Loss: 0.128199\n",
            "Iteration: 61 \t Training Loss: 0.127450\n",
            "Iteration: 71 \t Training Loss: 0.126846\n",
            "Iteration: 81 \t Training Loss: 0.126190\n",
            "Iteration: 91 \t Training Loss: 0.125781\n",
            "*--------*\n",
            "Epoch: 10 \t Training Loss: 0.125349\n",
            "Epoch: 10 \t Validation loss: 0.12, p: 0.75, r: 0.07, f1: 0.13\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.118906\n",
            "Iteration: 11 \t Training Loss: 0.121361\n",
            "Iteration: 21 \t Training Loss: 0.120094\n",
            "Iteration: 31 \t Training Loss: 0.118878\n",
            "Iteration: 41 \t Training Loss: 0.119084\n",
            "Iteration: 51 \t Training Loss: 0.118101\n",
            "Iteration: 61 \t Training Loss: 0.117471\n",
            "Iteration: 71 \t Training Loss: 0.116916\n",
            "Iteration: 81 \t Training Loss: 0.116762\n",
            "Iteration: 91 \t Training Loss: 0.116526\n",
            "*--------*\n",
            "Epoch: 11 \t Training Loss: 0.116763\n",
            "Epoch: 11 \t Validation loss: 0.11, p: 0.74, r: 0.07, f1: 0.13\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.113990\n",
            "Iteration: 11 \t Training Loss: 0.112520\n",
            "Iteration: 21 \t Training Loss: 0.112080\n",
            "Iteration: 31 \t Training Loss: 0.111823\n",
            "Iteration: 41 \t Training Loss: 0.111965\n",
            "Iteration: 51 \t Training Loss: 0.111330\n",
            "Iteration: 61 \t Training Loss: 0.111525\n",
            "Iteration: 71 \t Training Loss: 0.110835\n",
            "Iteration: 81 \t Training Loss: 0.110701\n",
            "Iteration: 91 \t Training Loss: 0.110622\n",
            "*--------*\n",
            "Epoch: 12 \t Training Loss: 0.110609\n",
            "Epoch: 12 \t Validation loss: 0.10, p: 0.74, r: 0.08, f1: 0.14\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.109946\n",
            "Iteration: 11 \t Training Loss: 0.108952\n",
            "Iteration: 21 \t Training Loss: 0.107384\n",
            "Iteration: 31 \t Training Loss: 0.107462\n",
            "Iteration: 41 \t Training Loss: 0.107047\n",
            "Iteration: 51 \t Training Loss: 0.106795\n",
            "Iteration: 61 \t Training Loss: 0.106781\n",
            "Iteration: 71 \t Training Loss: 0.106821\n",
            "Iteration: 81 \t Training Loss: 0.106651\n",
            "Iteration: 91 \t Training Loss: 0.106336\n",
            "*--------*\n",
            "Epoch: 13 \t Training Loss: 0.106136\n",
            "Epoch: 13 \t Validation loss: 0.10, p: 0.74, r: 0.08, f1: 0.14\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.109611\n",
            "Iteration: 11 \t Training Loss: 0.102943\n",
            "Iteration: 21 \t Training Loss: 0.103206\n",
            "Iteration: 31 \t Training Loss: 0.102437\n",
            "Iteration: 41 \t Training Loss: 0.103055\n",
            "Iteration: 51 \t Training Loss: 0.102908\n",
            "Iteration: 61 \t Training Loss: 0.103088\n",
            "Iteration: 71 \t Training Loss: 0.102895\n",
            "Iteration: 81 \t Training Loss: 0.103022\n",
            "Iteration: 91 \t Training Loss: 0.102969\n",
            "*--------*\n",
            "Epoch: 14 \t Training Loss: 0.102808\n",
            "Epoch: 14 \t Validation loss: 0.10, p: 0.74, r: 0.08, f1: 0.14\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.109022\n",
            "Iteration: 11 \t Training Loss: 0.101730\n",
            "Iteration: 21 \t Training Loss: 0.101062\n",
            "Iteration: 31 \t Training Loss: 0.102577\n",
            "Iteration: 41 \t Training Loss: 0.102367\n",
            "Iteration: 51 \t Training Loss: 0.101430\n",
            "Iteration: 61 \t Training Loss: 0.101441\n",
            "Iteration: 71 \t Training Loss: 0.100485\n",
            "Iteration: 81 \t Training Loss: 0.100593\n",
            "Iteration: 91 \t Training Loss: 0.100417\n",
            "*--------*\n",
            "Epoch: 15 \t Training Loss: 0.100258\n",
            "Epoch: 15 \t Validation loss: 0.10, p: 0.74, r: 0.08, f1: 0.14\n",
            "trigger times: 0\n"
          ]
        }
      ],
      "source": [
        "train(model_cat_0, train_dataloader, val_dataloader, nEpochs, optimizer_cat_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da701b2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da701b2d",
        "outputId": "d8bddc5e-b470-4a85-f4f3-743630c9fcee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.09409197945194908,\n",
              " 0.6565400843881856,\n",
              " 0.07373869664493563,\n",
              " 0.12987092563480096)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "eval_model(model_cat_0, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "761b154f",
      "metadata": {
        "id": "761b154f"
      },
      "source": [
        "### BOT Baseline w/ Cat 1 Dense "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81964f18",
      "metadata": {
        "id": "81964f18"
      },
      "outputs": [],
      "source": [
        "model_cat_1 = Model(vocabSize+1, numCodes, len(uniqueCats), 1, [120])\n",
        "optimizer_cat_1 = torch.optim.Adam(model_cat_1.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9958f527",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9958f527",
        "outputId": "496c18b6-4fcd-4c23-ebab-1ccdf162ce24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1 \t Training Loss: 0.708303\n",
            "Iteration: 11 \t Training Loss: 0.575477\n",
            "Iteration: 21 \t Training Loss: 0.468103\n",
            "Iteration: 31 \t Training Loss: 0.385046\n",
            "Iteration: 41 \t Training Loss: 0.325617\n",
            "Iteration: 51 \t Training Loss: 0.284005\n",
            "Iteration: 61 \t Training Loss: 0.254523\n",
            "Iteration: 71 \t Training Loss: 0.231711\n",
            "Iteration: 81 \t Training Loss: 0.215124\n",
            "Iteration: 91 \t Training Loss: 0.202204\n",
            "*--------*\n",
            "Epoch: 1 \t Training Loss: 0.193518\n",
            "Epoch: 1 \t Validation loss: 0.09, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.098797\n",
            "Iteration: 11 \t Training Loss: 0.095975\n",
            "Iteration: 21 \t Training Loss: 0.094770\n",
            "Iteration: 31 \t Training Loss: 0.093723\n",
            "Iteration: 41 \t Training Loss: 0.093295\n",
            "Iteration: 51 \t Training Loss: 0.093651\n",
            "Iteration: 61 \t Training Loss: 0.093302\n",
            "Iteration: 71 \t Training Loss: 0.092895\n",
            "Iteration: 81 \t Training Loss: 0.092474\n",
            "Iteration: 91 \t Training Loss: 0.092204\n",
            "*--------*\n",
            "Epoch: 2 \t Training Loss: 0.091992\n",
            "Epoch: 2 \t Validation loss: 0.09, p: 0.71, r: 0.10, f1: 0.17\n",
            "trigger times: 1\n",
            "Iteration: 1 \t Training Loss: 0.087641\n",
            "Iteration: 11 \t Training Loss: 0.088943\n",
            "Iteration: 21 \t Training Loss: 0.089195\n",
            "Iteration: 31 \t Training Loss: 0.089929\n",
            "Iteration: 41 \t Training Loss: 0.090220\n",
            "Iteration: 51 \t Training Loss: 0.090442\n",
            "Iteration: 61 \t Training Loss: 0.090844\n",
            "Iteration: 71 \t Training Loss: 0.091091\n",
            "Iteration: 81 \t Training Loss: 0.090936\n",
            "Iteration: 91 \t Training Loss: 0.091267\n",
            "*--------*\n",
            "Epoch: 3 \t Training Loss: 0.091106\n",
            "Epoch: 3 \t Validation loss: 0.09, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 2\n",
            "Iteration: 1 \t Training Loss: 0.097123\n",
            "Iteration: 11 \t Training Loss: 0.090647\n",
            "Iteration: 21 \t Training Loss: 0.090880\n",
            "Iteration: 31 \t Training Loss: 0.090869\n",
            "Iteration: 41 \t Training Loss: 0.090907\n",
            "Iteration: 51 \t Training Loss: 0.090867\n",
            "Iteration: 61 \t Training Loss: 0.091085\n",
            "Iteration: 71 \t Training Loss: 0.091264\n",
            "Iteration: 81 \t Training Loss: 0.091036\n",
            "Iteration: 91 \t Training Loss: 0.090652\n",
            "*--------*\n",
            "Epoch: 4 \t Training Loss: 0.090787\n",
            "Epoch: 4 \t Validation loss: 0.09, p: 0.84, r: 0.06, f1: 0.12\n",
            "trigger times: 3\n",
            "Iteration: 1 \t Training Loss: 0.099842\n",
            "Iteration: 11 \t Training Loss: 0.090737\n",
            "Iteration: 21 \t Training Loss: 0.091133\n",
            "Iteration: 31 \t Training Loss: 0.090545\n",
            "Iteration: 41 \t Training Loss: 0.090871\n",
            "Iteration: 51 \t Training Loss: 0.090815\n",
            "Iteration: 61 \t Training Loss: 0.090872\n",
            "Iteration: 71 \t Training Loss: 0.090879\n",
            "Iteration: 81 \t Training Loss: 0.090746\n",
            "Iteration: 91 \t Training Loss: 0.090706\n",
            "*--------*\n",
            "Epoch: 5 \t Training Loss: 0.090692\n",
            "Epoch: 5 \t Validation loss: 0.09, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 4\n",
            "Early stopping!\n",
            "Start to test process.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (embedding): Embedding(10932, 300)\n",
              "  (fc_layers): ModuleList(\n",
              "    (0): Linear(in_features=313, out_features=120, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              "  (fc_final): Linear(in_features=120, out_features=649, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "train(model_cat_1, train_dataloader, val_dataloader, nEpochs, optimizer_cat_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0c445db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0c445db",
        "outputId": "9dcc6799-0248-4f4f-ca0b-96c96f2a9c5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.09565376876087128,\n",
              " 0.569620253164557,\n",
              " 0.04238887639120817,\n",
              " 0.07824123362627106)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "eval_model(model_cat_1, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a78d67d7",
      "metadata": {
        "id": "a78d67d7"
      },
      "source": [
        "### BOT Baseline w/ Cat 2 Dense "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b98cddf0",
      "metadata": {
        "id": "b98cddf0"
      },
      "outputs": [],
      "source": [
        "model_cat_2 = Model(vocabSize+1, numCodes, len(uniqueCats), 2, [200, 100])\n",
        "optimizer_cat_2 = torch.optim.Adam(model_cat_2.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cac7f16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cac7f16",
        "outputId": "7e4a006e-a314-49e7-9f47-6cd35afb0774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1 \t Training Loss: 0.708341\n",
            "Iteration: 11 \t Training Loss: 0.585886\n",
            "Iteration: 21 \t Training Loss: 0.466138\n",
            "Iteration: 31 \t Training Loss: 0.372883\n",
            "Iteration: 41 \t Training Loss: 0.311251\n",
            "Iteration: 51 \t Training Loss: 0.270631\n",
            "Iteration: 61 \t Training Loss: 0.243202\n",
            "Iteration: 71 \t Training Loss: 0.223015\n",
            "Iteration: 81 \t Training Loss: 0.206897\n",
            "Iteration: 91 \t Training Loss: 0.193936\n",
            "*--------*\n",
            "Epoch: 1 \t Training Loss: 0.185876\n",
            "Epoch: 1 \t Validation loss: 0.09, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.091418\n",
            "Iteration: 11 \t Training Loss: 0.092973\n",
            "Iteration: 21 \t Training Loss: 0.092853\n",
            "Iteration: 31 \t Training Loss: 0.092963\n",
            "Iteration: 41 \t Training Loss: 0.092341\n",
            "Iteration: 51 \t Training Loss: 0.091493\n",
            "Iteration: 61 \t Training Loss: 0.091499\n",
            "Iteration: 71 \t Training Loss: 0.091508\n",
            "Iteration: 81 \t Training Loss: 0.091842\n",
            "Iteration: 91 \t Training Loss: 0.092073\n",
            "*--------*\n",
            "Epoch: 2 \t Training Loss: 0.091989\n",
            "Epoch: 2 \t Validation loss: 0.09, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 1\n",
            "Iteration: 1 \t Training Loss: 0.091834\n",
            "Iteration: 11 \t Training Loss: 0.089929\n",
            "Iteration: 21 \t Training Loss: 0.090121\n",
            "Iteration: 31 \t Training Loss: 0.090543\n",
            "Iteration: 41 \t Training Loss: 0.090833\n",
            "Iteration: 51 \t Training Loss: 0.090356\n",
            "Iteration: 61 \t Training Loss: 0.090080\n",
            "Iteration: 71 \t Training Loss: 0.090348\n",
            "Iteration: 81 \t Training Loss: 0.090547\n",
            "Iteration: 91 \t Training Loss: 0.090636\n",
            "*--------*\n",
            "Epoch: 3 \t Training Loss: 0.091225\n",
            "Epoch: 3 \t Validation loss: 0.09, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 2\n",
            "Iteration: 1 \t Training Loss: 0.096979\n",
            "Iteration: 11 \t Training Loss: 0.089998\n",
            "Iteration: 21 \t Training Loss: 0.090273\n",
            "Iteration: 31 \t Training Loss: 0.089864\n",
            "Iteration: 41 \t Training Loss: 0.090122\n",
            "Iteration: 51 \t Training Loss: 0.090488\n",
            "Iteration: 61 \t Training Loss: 0.091122\n",
            "Iteration: 71 \t Training Loss: 0.091187\n",
            "Iteration: 81 \t Training Loss: 0.091101\n",
            "Iteration: 91 \t Training Loss: 0.090923\n",
            "*--------*\n",
            "Epoch: 4 \t Training Loss: 0.091127\n",
            "Epoch: 4 \t Validation loss: 0.09, p: 0.71, r: 0.10, f1: 0.17\n",
            "trigger times: 3\n",
            "Iteration: 1 \t Training Loss: 0.089703\n",
            "Iteration: 11 \t Training Loss: 0.091631\n",
            "Iteration: 21 \t Training Loss: 0.091225\n",
            "Iteration: 31 \t Training Loss: 0.091746\n",
            "Iteration: 41 \t Training Loss: 0.091071\n",
            "Iteration: 51 \t Training Loss: 0.091554\n",
            "Iteration: 61 \t Training Loss: 0.091765\n",
            "Iteration: 71 \t Training Loss: 0.091294\n",
            "Iteration: 81 \t Training Loss: 0.090994\n",
            "Iteration: 91 \t Training Loss: 0.090793\n",
            "*--------*\n",
            "Epoch: 5 \t Training Loss: 0.091061\n",
            "Epoch: 5 \t Validation loss: 0.09, p: 0.71, r: 0.10, f1: 0.17\n",
            "trigger times: 4\n",
            "Early stopping!\n",
            "Start to test process.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (embedding): Embedding(10932, 300)\n",
              "  (fc_layers): ModuleList(\n",
              "    (0): Linear(in_features=313, out_features=200, bias=True)\n",
              "    (1): Sigmoid()\n",
              "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
              "    (3): Sigmoid()\n",
              "  )\n",
              "  (fc_final): Linear(in_features=100, out_features=649, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "train(model_cat_2, train_dataloader, val_dataloader, nEpochs, optimizer_cat_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcf3b83d",
      "metadata": {
        "id": "fcf3b83d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea8c01b-28af-4eaf-f488-75321d1810e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.09607145641989345,\n",
              " 0.6278481012658228,\n",
              " 0.08782857159300315,\n",
              " 0.15251033077033135)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "eval_model(model_cat_2, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "144f8fcc",
      "metadata": {
        "id": "144f8fcc"
      },
      "source": [
        "### BOT Baseline w/ Cat 3 Dense "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08ae90ef",
      "metadata": {
        "id": "08ae90ef"
      },
      "outputs": [],
      "source": [
        "model_cat_3 = Model(vocabSize+1, numCodes, len(uniqueCats), 3, [230, 170, 110])\n",
        "optimizer_cat_3 = torch.optim.Adam(model_cat_3.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb6ca7de",
      "metadata": {
        "id": "cb6ca7de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8889968-6e87-495b-fb6c-67b216f5f7cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1 \t Training Loss: 0.703343\n",
            "Iteration: 11 \t Training Loss: 0.689539\n",
            "Iteration: 21 \t Training Loss: 0.675695\n",
            "Iteration: 31 \t Training Loss: 0.662110\n",
            "Iteration: 41 \t Training Loss: 0.648427\n",
            "Iteration: 51 \t Training Loss: 0.634524\n",
            "Iteration: 61 \t Training Loss: 0.620221\n",
            "Iteration: 71 \t Training Loss: 0.605448\n",
            "Iteration: 81 \t Training Loss: 0.590238\n",
            "Iteration: 91 \t Training Loss: 0.574664\n",
            "*--------*\n",
            "Epoch: 1 \t Training Loss: 0.561970\n",
            "Epoch: 1 \t Validation loss: 0.40, p: 0.07, r: 0.10, f1: 0.08\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.403444\n",
            "Iteration: 11 \t Training Loss: 0.387686\n",
            "Iteration: 21 \t Training Loss: 0.372086\n",
            "Iteration: 31 \t Training Loss: 0.357699\n",
            "Iteration: 41 \t Training Loss: 0.344063\n",
            "Iteration: 51 \t Training Loss: 0.331059\n",
            "Iteration: 61 \t Training Loss: 0.319479\n",
            "Iteration: 71 \t Training Loss: 0.308802\n",
            "Iteration: 81 \t Training Loss: 0.298639\n",
            "Iteration: 91 \t Training Loss: 0.289231\n",
            "*--------*\n",
            "Epoch: 2 \t Training Loss: 0.282271\n",
            "Epoch: 2 \t Validation loss: 0.19, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.201651\n",
            "Iteration: 11 \t Training Loss: 0.196320\n",
            "Iteration: 21 \t Training Loss: 0.191890\n",
            "Iteration: 31 \t Training Loss: 0.186370\n",
            "Iteration: 41 \t Training Loss: 0.182211\n",
            "Iteration: 51 \t Training Loss: 0.179519\n",
            "Iteration: 61 \t Training Loss: 0.176735\n",
            "Iteration: 71 \t Training Loss: 0.173640\n",
            "Iteration: 81 \t Training Loss: 0.170643\n",
            "Iteration: 91 \t Training Loss: 0.167755\n",
            "*--------*\n",
            "Epoch: 3 \t Training Loss: 0.165816\n",
            "Epoch: 3 \t Validation loss: 0.14, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.137697\n",
            "Iteration: 11 \t Training Loss: 0.138131\n",
            "Iteration: 21 \t Training Loss: 0.137046\n",
            "Iteration: 31 \t Training Loss: 0.136187\n",
            "Iteration: 41 \t Training Loss: 0.135048\n",
            "Iteration: 51 \t Training Loss: 0.134336\n",
            "Iteration: 61 \t Training Loss: 0.133592\n",
            "Iteration: 71 \t Training Loss: 0.132236\n",
            "Iteration: 81 \t Training Loss: 0.131337\n",
            "Iteration: 91 \t Training Loss: 0.130325\n",
            "*--------*\n",
            "Epoch: 4 \t Training Loss: 0.129420\n",
            "Epoch: 4 \t Validation loss: 0.11, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.113951\n",
            "Iteration: 11 \t Training Loss: 0.118626\n",
            "Iteration: 21 \t Training Loss: 0.118233\n",
            "Iteration: 31 \t Training Loss: 0.118179\n",
            "Iteration: 41 \t Training Loss: 0.118050\n",
            "Iteration: 51 \t Training Loss: 0.116887\n",
            "Iteration: 61 \t Training Loss: 0.116246\n",
            "Iteration: 71 \t Training Loss: 0.115344\n",
            "Iteration: 81 \t Training Loss: 0.114700\n",
            "Iteration: 91 \t Training Loss: 0.114279\n",
            "*--------*\n",
            "Epoch: 5 \t Training Loss: 0.113762\n",
            "Epoch: 5 \t Validation loss: 0.10, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.112867\n",
            "Iteration: 11 \t Training Loss: 0.109916\n",
            "Iteration: 21 \t Training Loss: 0.108726\n",
            "Iteration: 31 \t Training Loss: 0.109190\n",
            "Iteration: 41 \t Training Loss: 0.108471\n",
            "Iteration: 51 \t Training Loss: 0.108425\n",
            "Iteration: 61 \t Training Loss: 0.107361\n",
            "Iteration: 71 \t Training Loss: 0.106460\n",
            "Iteration: 81 \t Training Loss: 0.106299\n",
            "Iteration: 91 \t Training Loss: 0.106078\n",
            "*--------*\n",
            "Epoch: 6 \t Training Loss: 0.105673\n",
            "Epoch: 6 \t Validation loss: 0.10, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.100352\n",
            "Iteration: 11 \t Training Loss: 0.101582\n",
            "Iteration: 21 \t Training Loss: 0.101019\n",
            "Iteration: 31 \t Training Loss: 0.101378\n",
            "Iteration: 41 \t Training Loss: 0.101642\n",
            "Iteration: 51 \t Training Loss: 0.101628\n",
            "Iteration: 61 \t Training Loss: 0.101416\n",
            "Iteration: 71 \t Training Loss: 0.100977\n",
            "Iteration: 81 \t Training Loss: 0.100790\n",
            "Iteration: 91 \t Training Loss: 0.101017\n",
            "*--------*\n",
            "Epoch: 7 \t Training Loss: 0.100967\n",
            "Epoch: 7 \t Validation loss: 0.09, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.098362\n",
            "Iteration: 11 \t Training Loss: 0.097050\n",
            "Iteration: 21 \t Training Loss: 0.098948\n",
            "Iteration: 31 \t Training Loss: 0.099341\n",
            "Iteration: 41 \t Training Loss: 0.099206\n",
            "Iteration: 51 \t Training Loss: 0.099644\n",
            "Iteration: 61 \t Training Loss: 0.099223\n",
            "Iteration: 71 \t Training Loss: 0.098746\n",
            "Iteration: 81 \t Training Loss: 0.098650\n",
            "Iteration: 91 \t Training Loss: 0.098437\n",
            "*--------*\n",
            "Epoch: 8 \t Training Loss: 0.098023\n",
            "Epoch: 8 \t Validation loss: 0.09, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.107070\n",
            "Iteration: 11 \t Training Loss: 0.098065\n",
            "Iteration: 21 \t Training Loss: 0.097285\n",
            "Iteration: 31 \t Training Loss: 0.096794\n",
            "Iteration: 41 \t Training Loss: 0.096741\n",
            "Iteration: 51 \t Training Loss: 0.096742\n",
            "Iteration: 61 \t Training Loss: 0.097023\n",
            "Iteration: 71 \t Training Loss: 0.097221\n",
            "Iteration: 81 \t Training Loss: 0.096655\n",
            "Iteration: 91 \t Training Loss: 0.096316\n",
            "*--------*\n",
            "Epoch: 9 \t Training Loss: 0.096168\n",
            "Epoch: 9 \t Validation loss: 0.09, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.094228\n",
            "Iteration: 11 \t Training Loss: 0.093115\n",
            "Iteration: 21 \t Training Loss: 0.094754\n",
            "Iteration: 31 \t Training Loss: 0.094616\n",
            "Iteration: 41 \t Training Loss: 0.094825\n",
            "Iteration: 51 \t Training Loss: 0.094385\n",
            "Iteration: 61 \t Training Loss: 0.094482\n",
            "Iteration: 71 \t Training Loss: 0.094919\n",
            "Iteration: 81 \t Training Loss: 0.094685\n",
            "Iteration: 91 \t Training Loss: 0.094759\n",
            "*--------*\n",
            "Epoch: 10 \t Training Loss: 0.094836\n",
            "Epoch: 10 \t Validation loss: 0.09, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.086165\n",
            "Iteration: 11 \t Training Loss: 0.095223\n",
            "Iteration: 21 \t Training Loss: 0.094204\n",
            "Iteration: 31 \t Training Loss: 0.093909\n",
            "Iteration: 41 \t Training Loss: 0.093785\n",
            "Iteration: 51 \t Training Loss: 0.093794\n",
            "Iteration: 61 \t Training Loss: 0.093419\n",
            "Iteration: 71 \t Training Loss: 0.093401\n",
            "Iteration: 81 \t Training Loss: 0.093547\n",
            "Iteration: 91 \t Training Loss: 0.093582\n",
            "*--------*\n",
            "Epoch: 11 \t Training Loss: 0.093877\n",
            "Epoch: 11 \t Validation loss: 0.09, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.102646\n",
            "Iteration: 11 \t Training Loss: 0.094996\n",
            "Iteration: 21 \t Training Loss: 0.095622\n",
            "Iteration: 31 \t Training Loss: 0.096041\n",
            "Iteration: 41 \t Training Loss: 0.094745\n",
            "Iteration: 51 \t Training Loss: 0.094063\n",
            "Iteration: 61 \t Training Loss: 0.094220\n",
            "Iteration: 71 \t Training Loss: 0.093967\n",
            "Iteration: 81 \t Training Loss: 0.093687\n",
            "Iteration: 91 \t Training Loss: 0.093570\n",
            "*--------*\n",
            "Epoch: 12 \t Training Loss: 0.093158\n",
            "Epoch: 12 \t Validation loss: 0.09, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.094497\n",
            "Iteration: 11 \t Training Loss: 0.093451\n",
            "Iteration: 21 \t Training Loss: 0.092879\n",
            "Iteration: 31 \t Training Loss: 0.093274\n",
            "Iteration: 41 \t Training Loss: 0.093579\n",
            "Iteration: 51 \t Training Loss: 0.093596\n",
            "Iteration: 61 \t Training Loss: 0.092710\n",
            "Iteration: 71 \t Training Loss: 0.093022\n",
            "Iteration: 81 \t Training Loss: 0.092904\n",
            "Iteration: 91 \t Training Loss: 0.092725\n",
            "*--------*\n",
            "Epoch: 13 \t Training Loss: 0.092651\n",
            "Epoch: 13 \t Validation loss: 0.09, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 1\n",
            "Iteration: 1 \t Training Loss: 0.087221\n",
            "Iteration: 11 \t Training Loss: 0.090897\n",
            "Iteration: 21 \t Training Loss: 0.092087\n",
            "Iteration: 31 \t Training Loss: 0.092708\n",
            "Iteration: 41 \t Training Loss: 0.092519\n",
            "Iteration: 51 \t Training Loss: 0.092909\n",
            "Iteration: 61 \t Training Loss: 0.092671\n",
            "Iteration: 71 \t Training Loss: 0.092866\n",
            "Iteration: 81 \t Training Loss: 0.092721\n",
            "Iteration: 91 \t Training Loss: 0.092626\n",
            "*--------*\n",
            "Epoch: 14 \t Training Loss: 0.092256\n",
            "Epoch: 14 \t Validation loss: 0.09, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.092650\n",
            "Iteration: 11 \t Training Loss: 0.092577\n",
            "Iteration: 21 \t Training Loss: 0.093947\n",
            "Iteration: 31 \t Training Loss: 0.093131\n",
            "Iteration: 41 \t Training Loss: 0.093181\n",
            "Iteration: 51 \t Training Loss: 0.092584\n",
            "Iteration: 61 \t Training Loss: 0.092298\n",
            "Iteration: 71 \t Training Loss: 0.092349\n",
            "Iteration: 81 \t Training Loss: 0.091935\n",
            "Iteration: 91 \t Training Loss: 0.091838\n",
            "*--------*\n",
            "Epoch: 15 \t Training Loss: 0.091982\n",
            "Epoch: 15 \t Validation loss: 0.09, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 1\n"
          ]
        }
      ],
      "source": [
        "train(model_cat_3, train_dataloader, val_dataloader, nEpochs, optimizer_cat_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3020d0a9",
      "metadata": {
        "id": "3020d0a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f47a92-e60e-40b3-ab58-f83942a682e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.08941374425835247,\n",
              " 0.569620253164557,\n",
              " 0.04238887639120817,\n",
              " 0.07824123362627106)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "eval_model(model_cat_3, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cb7a385",
      "metadata": {
        "id": "5cb7a385"
      },
      "source": [
        "### CNN Baseline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1584b56",
      "metadata": {
        "id": "e1584b56"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):    \n",
        "    def __init__(self, num_words, out_classes, nCats, category_layers=-1, hidden_sizes=None):\n",
        "        super().__init__()\n",
        "        self.category_layers = category_layers\n",
        "        self.embedding = nn.Embedding(num_embeddings=num_words, embedding_dim=300)\n",
        "        self.conv = nn.Conv1d(300, 3, 250)\n",
        "        self.maxpool = nn.MaxPool1d(3, 2)\n",
        "        prev_size = (3*(((max_report_len-252)//2)+1))\n",
        "        self.fc_layers = nn.ModuleList()\n",
        "        if category_layers > -1:\n",
        "            prev_size += nCats\n",
        "        if category_layers > 0:\n",
        "            for hsize in hidden_sizes:\n",
        "                self.fc_layers.append(nn.Linear(prev_size, hsize))\n",
        "                self.fc_layers.append(nn.Sigmoid())\n",
        "                prev_size = hsize\n",
        "        self.fc_final = nn.Linear(in_features=prev_size, out_features=out_classes)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x, mask, cat):\n",
        "        x = self.embedding(x)\n",
        "        maskUnsq = mask.unsqueeze(-1)\n",
        "        x = x*maskUnsq    # 32 x max_size x 300\n",
        "        x = torch.permute(x, (0, 2, 1)) # 32 x 300 x max_size\n",
        "        x = F.relu(self.conv(x)) # 32 x 3 x (max_size-249)\n",
        "        x = self.maxpool(x)   # 32 x 3 x ((max_size-252)//2)+1\n",
        "        x = torch.flatten(x, 1, -1) # 32 x (3*(((max_size-252)//2)+1))\n",
        "        if(self.category_layers != -1):\n",
        "            x = torch.cat((cat, x), dim=1)\n",
        "        if(self.category_layers > 0):\n",
        "            for fc_layer in self.fc_layers:\n",
        "                x = fc_layer(x)\n",
        "        x = self.fc_final(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25a30a19",
      "metadata": {
        "id": "25a30a19"
      },
      "source": [
        "### CNN Baseline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66471681",
      "metadata": {
        "id": "66471681"
      },
      "outputs": [],
      "source": [
        "cnn_model_cat_m1 = CNNModel(vocabSize+1, numCodes, len(uniqueCats))\n",
        "cnn_optimizer_cat_m1 = torch.optim.Adam(cnn_model_cat_m1.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a888208",
      "metadata": {
        "id": "4a888208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "580f62db-0f7c-4d12-a168-86e51b33dde2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (embedding): Embedding(10932, 300)\n",
              "  (conv): Conv1d(300, 3, kernel_size=(250,), stride=(1,))\n",
              "  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc_layers): ModuleList()\n",
              "  (fc_final): Linear(in_features=2901, out_features=649, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "cnn_model_cat_m1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80734d53",
      "metadata": {
        "id": "80734d53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f50693ca-4300-4981-eee2-b5f9ce980d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1 \t Training Loss: 0.692948\n",
            "Iteration: 11 \t Training Loss: 0.391436\n",
            "Iteration: 21 \t Training Loss: 0.305742\n",
            "Iteration: 31 \t Training Loss: 0.249215\n",
            "Iteration: 41 \t Training Loss: 0.214773\n",
            "*--------*\n",
            "Epoch: 1 \t Training Loss: 0.194227\n",
            "Epoch: 1 \t Validation loss: 0.11, p: 0.74, r: 0.10, f1: 0.18\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.108223\n",
            "Iteration: 11 \t Training Loss: 0.095536\n",
            "Iteration: 21 \t Training Loss: 0.093380\n",
            "Iteration: 31 \t Training Loss: 0.091904\n",
            "Iteration: 41 \t Training Loss: 0.091315\n",
            "*--------*\n",
            "Epoch: 2 \t Training Loss: 0.091293\n",
            "Epoch: 2 \t Validation loss: 0.10, p: 0.74, r: 0.08, f1: 0.15\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.077132\n",
            "Iteration: 11 \t Training Loss: 0.083777\n",
            "Iteration: 21 \t Training Loss: 0.083554\n",
            "Iteration: 31 \t Training Loss: 0.083461\n",
            "Iteration: 41 \t Training Loss: 0.083366\n",
            "*--------*\n",
            "Epoch: 3 \t Training Loss: 0.083427\n",
            "Epoch: 3 \t Validation loss: 0.11, p: 0.71, r: 0.09, f1: 0.15\n",
            "trigger times: 1\n",
            "Iteration: 1 \t Training Loss: 0.083339\n",
            "Iteration: 11 \t Training Loss: 0.076173\n",
            "Iteration: 21 \t Training Loss: 0.076581\n",
            "Iteration: 31 \t Training Loss: 0.076706\n",
            "Iteration: 41 \t Training Loss: 0.076922\n",
            "*--------*\n",
            "Epoch: 4 \t Training Loss: 0.077132\n",
            "Epoch: 4 \t Validation loss: 0.12, p: 0.69, r: 0.10, f1: 0.16\n",
            "trigger times: 2\n",
            "Iteration: 1 \t Training Loss: 0.070413\n",
            "Iteration: 11 \t Training Loss: 0.070569\n",
            "Iteration: 21 \t Training Loss: 0.068984\n",
            "Iteration: 31 \t Training Loss: 0.069040\n",
            "Iteration: 41 \t Training Loss: 0.069568\n",
            "*--------*\n",
            "Epoch: 5 \t Training Loss: 0.069726\n",
            "Epoch: 5 \t Validation loss: 0.13, p: 0.62, r: 0.11, f1: 0.17\n",
            "trigger times: 3\n",
            "Iteration: 1 \t Training Loss: 0.061956\n",
            "Iteration: 11 \t Training Loss: 0.061804\n",
            "Iteration: 21 \t Training Loss: 0.061247\n",
            "Iteration: 31 \t Training Loss: 0.060862\n",
            "Iteration: 41 \t Training Loss: 0.061236\n",
            "*--------*\n",
            "Epoch: 6 \t Training Loss: 0.060903\n",
            "Epoch: 6 \t Validation loss: 0.14, p: 0.58, r: 0.12, f1: 0.19\n",
            "trigger times: 4\n",
            "Early stopping!\n",
            "Start to test process.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (embedding): Embedding(10932, 300)\n",
              "  (conv): Conv1d(300, 3, kernel_size=(250,), stride=(1,))\n",
              "  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc_layers): ModuleList()\n",
              "  (fc_final): Linear(in_features=2901, out_features=649, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "train(cnn_model_cat_m1, train_dataloader, val_dataloader, nEpochs, cnn_optimizer_cat_m1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "905c71ae",
      "metadata": {
        "id": "905c71ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a2dd194-e351-4fa3-a754-94086bdca336"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.14461916897978103,\n",
              " 0.5067497513080407,\n",
              " 0.11061715254782621,\n",
              " 0.16800660734235345)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "eval_model(cnn_model_cat_m1, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03eeb11a",
      "metadata": {
        "id": "03eeb11a"
      },
      "source": [
        "### CNN Baseline w/ Cat 0 Dense "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a313442",
      "metadata": {
        "id": "0a313442"
      },
      "outputs": [],
      "source": [
        "cnn_model_cat_0 = CNNModel(vocabSize+1, numCodes, len(uniqueCats), 0)\n",
        "cnn_optimizer_cat_0 = torch.optim.Adam(cnn_model_cat_0.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0950cca",
      "metadata": {
        "id": "c0950cca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "799b905a-8fdd-4b5e-c5ba-e53bb8395865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1 \t Training Loss: 0.694831\n",
            "Iteration: 11 \t Training Loss: 0.398682\n",
            "Iteration: 21 \t Training Loss: 0.289108\n",
            "Iteration: 31 \t Training Loss: 0.234336\n",
            "Iteration: 41 \t Training Loss: 0.203598\n",
            "*--------*\n",
            "Epoch: 1 \t Training Loss: 0.185440\n",
            "Epoch: 1 \t Validation loss: 0.11, p: 0.75, r: 0.11, f1: 0.18\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.093387\n",
            "Iteration: 11 \t Training Loss: 0.093200\n",
            "Iteration: 21 \t Training Loss: 0.093118\n",
            "Iteration: 31 \t Training Loss: 0.092976\n",
            "Iteration: 41 \t Training Loss: 0.092184\n",
            "*--------*\n",
            "Epoch: 2 \t Training Loss: 0.091490\n",
            "Epoch: 2 \t Validation loss: 0.10, p: 0.76, r: 0.09, f1: 0.16\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.081804\n",
            "Iteration: 11 \t Training Loss: 0.082898\n",
            "Iteration: 21 \t Training Loss: 0.085185\n",
            "Iteration: 31 \t Training Loss: 0.085207\n",
            "Iteration: 41 \t Training Loss: 0.084320\n",
            "*--------*\n",
            "Epoch: 3 \t Training Loss: 0.084139\n",
            "Epoch: 3 \t Validation loss: 0.11, p: 0.72, r: 0.09, f1: 0.16\n",
            "trigger times: 1\n",
            "Iteration: 1 \t Training Loss: 0.074976\n",
            "Iteration: 11 \t Training Loss: 0.079069\n",
            "Iteration: 21 \t Training Loss: 0.078529\n",
            "Iteration: 31 \t Training Loss: 0.078484\n",
            "Iteration: 41 \t Training Loss: 0.078212\n",
            "*--------*\n",
            "Epoch: 4 \t Training Loss: 0.077754\n",
            "Epoch: 4 \t Validation loss: 0.12, p: 0.65, r: 0.11, f1: 0.17\n",
            "trigger times: 2\n",
            "Iteration: 1 \t Training Loss: 0.069913\n",
            "Iteration: 11 \t Training Loss: 0.070638\n",
            "Iteration: 21 \t Training Loss: 0.069971\n",
            "Iteration: 31 \t Training Loss: 0.069782\n",
            "Iteration: 41 \t Training Loss: 0.069676\n",
            "*--------*\n",
            "Epoch: 5 \t Training Loss: 0.070109\n",
            "Epoch: 5 \t Validation loss: 0.13, p: 0.64, r: 0.11, f1: 0.18\n",
            "trigger times: 3\n",
            "Iteration: 1 \t Training Loss: 0.057720\n",
            "Iteration: 11 \t Training Loss: 0.061990\n",
            "Iteration: 21 \t Training Loss: 0.061830\n",
            "Iteration: 31 \t Training Loss: 0.061321\n",
            "Iteration: 41 \t Training Loss: 0.060645\n",
            "*--------*\n",
            "Epoch: 6 \t Training Loss: 0.060546\n",
            "Epoch: 6 \t Validation loss: 0.15, p: 0.58, r: 0.10, f1: 0.16\n",
            "trigger times: 4\n",
            "Early stopping!\n",
            "Start to test process.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (embedding): Embedding(10932, 300)\n",
              "  (conv): Conv1d(300, 3, kernel_size=(250,), stride=(1,))\n",
              "  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc_layers): ModuleList()\n",
              "  (fc_final): Linear(in_features=2914, out_features=649, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "train(cnn_model_cat_0, train_dataloader, val_dataloader, nEpochs, cnn_optimizer_cat_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bbce96d",
      "metadata": {
        "id": "7bbce96d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b864e8a6-6c61-4647-941e-40b7077cf93f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.1420590387923377,\n",
              " 0.4885071709587778,\n",
              " 0.10913527394344105,\n",
              " 0.1603614585368459)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "eval_model(cnn_model_cat_0, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc7dac11",
      "metadata": {
        "id": "bc7dac11"
      },
      "source": [
        "### CNN Baseline w/ Cat 1 Dense "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89936c79",
      "metadata": {
        "id": "89936c79"
      },
      "outputs": [],
      "source": [
        "cnn_model_cat_1 = CNNModel(vocabSize+1, numCodes,len(uniqueCats), 1, [3000])\n",
        "cnn_optimizer_cat_1 = torch.optim.Adam(cnn_model_cat_1.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "021ef621",
      "metadata": {
        "id": "021ef621",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a92ab528-d0a0-4c1e-dd58-9fe780268ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1 \t Training Loss: 0.703784\n",
            "Iteration: 11 \t Training Loss: 0.180150\n",
            "Iteration: 21 \t Training Loss: 0.142965\n",
            "Iteration: 31 \t Training Loss: 0.127438\n",
            "Iteration: 41 \t Training Loss: 0.119975\n",
            "*--------*\n",
            "Epoch: 1 \t Training Loss: 0.114819\n",
            "Epoch: 1 \t Validation loss: 0.10, p: 0.85, r: 0.06, f1: 0.11\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.089805\n",
            "Iteration: 11 \t Training Loss: 0.093528\n",
            "Iteration: 21 \t Training Loss: 0.091884\n",
            "Iteration: 31 \t Training Loss: 0.090997\n",
            "Iteration: 41 \t Training Loss: 0.091233\n",
            "*--------*\n",
            "Epoch: 2 \t Training Loss: 0.091357\n",
            "Epoch: 2 \t Validation loss: 0.10, p: 0.78, r: 0.14, f1: 0.23\n",
            "trigger times: 1\n",
            "Iteration: 1 \t Training Loss: 0.089832\n",
            "Iteration: 11 \t Training Loss: 0.091027\n",
            "Iteration: 21 \t Training Loss: 0.089963\n",
            "Iteration: 31 \t Training Loss: 0.089196\n",
            "Iteration: 41 \t Training Loss: 0.089338\n",
            "*--------*\n",
            "Epoch: 3 \t Training Loss: 0.089247\n",
            "Epoch: 3 \t Validation loss: 0.10, p: 0.69, r: 0.11, f1: 0.19\n",
            "trigger times: 2\n",
            "Iteration: 1 \t Training Loss: 0.083871\n",
            "Iteration: 11 \t Training Loss: 0.086094\n",
            "Iteration: 21 \t Training Loss: 0.084811\n",
            "Iteration: 31 \t Training Loss: 0.084718\n",
            "Iteration: 41 \t Training Loss: 0.084413\n",
            "*--------*\n",
            "Epoch: 4 \t Training Loss: 0.084067\n",
            "Epoch: 4 \t Validation loss: 0.11, p: 0.64, r: 0.10, f1: 0.15\n",
            "trigger times: 3\n",
            "Iteration: 1 \t Training Loss: 0.080635\n",
            "Iteration: 11 \t Training Loss: 0.078215\n",
            "Iteration: 21 \t Training Loss: 0.078132\n",
            "Iteration: 31 \t Training Loss: 0.077682\n",
            "Iteration: 41 \t Training Loss: 0.077428\n",
            "*--------*\n",
            "Epoch: 5 \t Training Loss: 0.076889\n",
            "Epoch: 5 \t Validation loss: 0.10, p: 0.59, r: 0.07, f1: 0.12\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.071100\n",
            "Iteration: 11 \t Training Loss: 0.070009\n",
            "Iteration: 21 \t Training Loss: 0.071341\n",
            "Iteration: 31 \t Training Loss: 0.071362\n",
            "Iteration: 41 \t Training Loss: 0.070884\n",
            "*--------*\n",
            "Epoch: 6 \t Training Loss: 0.070210\n",
            "Epoch: 6 \t Validation loss: 0.11, p: 0.55, r: 0.11, f1: 0.16\n",
            "trigger times: 1\n",
            "Iteration: 1 \t Training Loss: 0.056709\n",
            "Iteration: 11 \t Training Loss: 0.062671\n",
            "Iteration: 21 \t Training Loss: 0.062632\n",
            "Iteration: 31 \t Training Loss: 0.062470\n",
            "Iteration: 41 \t Training Loss: 0.062042\n",
            "*--------*\n",
            "Epoch: 7 \t Training Loss: 0.061957\n",
            "Epoch: 7 \t Validation loss: 0.11, p: 0.64, r: 0.11, f1: 0.17\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.054746\n",
            "Iteration: 11 \t Training Loss: 0.054307\n",
            "Iteration: 21 \t Training Loss: 0.054404\n",
            "Iteration: 31 \t Training Loss: 0.053645\n",
            "Iteration: 41 \t Training Loss: 0.053151\n",
            "*--------*\n",
            "Epoch: 8 \t Training Loss: 0.053079\n",
            "Epoch: 8 \t Validation loss: 0.12, p: 0.49, r: 0.11, f1: 0.16\n",
            "trigger times: 1\n",
            "Iteration: 1 \t Training Loss: 0.041560\n",
            "Iteration: 11 \t Training Loss: 0.046115\n",
            "Iteration: 21 \t Training Loss: 0.044831\n",
            "Iteration: 31 \t Training Loss: 0.044739\n",
            "Iteration: 41 \t Training Loss: 0.044927\n",
            "*--------*\n",
            "Epoch: 9 \t Training Loss: 0.044679\n",
            "Epoch: 9 \t Validation loss: 0.12, p: 0.48, r: 0.11, f1: 0.17\n",
            "trigger times: 2\n",
            "Iteration: 1 \t Training Loss: 0.032143\n",
            "Iteration: 11 \t Training Loss: 0.037443\n",
            "Iteration: 21 \t Training Loss: 0.037166\n",
            "Iteration: 31 \t Training Loss: 0.036847\n",
            "Iteration: 41 \t Training Loss: 0.036633\n",
            "*--------*\n",
            "Epoch: 10 \t Training Loss: 0.036637\n",
            "Epoch: 10 \t Validation loss: 0.13, p: 0.44, r: 0.13, f1: 0.18\n",
            "trigger times: 3\n",
            "Iteration: 1 \t Training Loss: 0.038442\n",
            "Iteration: 11 \t Training Loss: 0.030675\n",
            "Iteration: 21 \t Training Loss: 0.030569\n",
            "Iteration: 31 \t Training Loss: 0.030565\n",
            "Iteration: 41 \t Training Loss: 0.030473\n",
            "*--------*\n",
            "Epoch: 11 \t Training Loss: 0.030126\n",
            "Epoch: 11 \t Validation loss: 0.13, p: 0.45, r: 0.12, f1: 0.17\n",
            "trigger times: 4\n",
            "Early stopping!\n",
            "Start to test process.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (embedding): Embedding(10932, 300)\n",
              "  (conv): Conv1d(300, 3, kernel_size=(250,), stride=(1,))\n",
              "  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc_layers): ModuleList(\n",
              "    (0): Linear(in_features=2914, out_features=3000, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              "  (fc_final): Linear(in_features=3000, out_features=649, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "train(cnn_model_cat_1, train_dataloader, val_dataloader, nEpochs, cnn_optimizer_cat_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55629d90",
      "metadata": {
        "id": "55629d90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5be77602-831e-481d-c350-929da21982fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.13450709411076137,\n",
              " 0.37006827645413415,\n",
              " 0.0989203216608084,\n",
              " 0.14674322703891687)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "eval_model(cnn_model_cat_1, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddcd51c5",
      "metadata": {
        "id": "ddcd51c5"
      },
      "source": [
        "### CNN Baseline w/ Cat 2 Dense "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "132311d2",
      "metadata": {
        "id": "132311d2"
      },
      "outputs": [],
      "source": [
        "cnn_model_cat_2 = CNNModel(vocabSize+1, numCodes, len(uniqueCats), 2, [3000, 500])\n",
        "cnn_optimizer_cat_2 = torch.optim.Adam(cnn_model_cat_2.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "017715ba",
      "metadata": {
        "id": "017715ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "399c2678-f53c-45fe-cd18-5422f471002e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1 \t Training Loss: 0.704971\n",
            "Iteration: 11 \t Training Loss: 0.294200\n",
            "Iteration: 21 \t Training Loss: 0.201765\n",
            "Iteration: 31 \t Training Loss: 0.167068\n",
            "Iteration: 41 \t Training Loss: 0.148904\n",
            "*--------*\n",
            "Epoch: 1 \t Training Loss: 0.139122\n",
            "Epoch: 1 \t Validation loss: 0.09, p: 0.85, r: 0.11, f1: 0.19\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.093766\n",
            "Iteration: 11 \t Training Loss: 0.093849\n",
            "Iteration: 21 \t Training Loss: 0.091988\n",
            "Iteration: 31 \t Training Loss: 0.092504\n",
            "Iteration: 41 \t Training Loss: 0.091775\n",
            "*--------*\n",
            "Epoch: 2 \t Training Loss: 0.091382\n",
            "Epoch: 2 \t Validation loss: 0.10, p: 0.71, r: 0.10, f1: 0.17\n",
            "trigger times: 1\n",
            "Iteration: 1 \t Training Loss: 0.091420\n",
            "Iteration: 11 \t Training Loss: 0.093645\n",
            "Iteration: 21 \t Training Loss: 0.092197\n",
            "Iteration: 31 \t Training Loss: 0.091985\n",
            "Iteration: 41 \t Training Loss: 0.091500\n",
            "*--------*\n",
            "Epoch: 3 \t Training Loss: 0.091165\n",
            "Epoch: 3 \t Validation loss: 0.10, p: 0.71, r: 0.10, f1: 0.17\n",
            "trigger times: 2\n",
            "Iteration: 1 \t Training Loss: 0.087489\n",
            "Iteration: 11 \t Training Loss: 0.090956\n",
            "Iteration: 21 \t Training Loss: 0.091321\n",
            "Iteration: 31 \t Training Loss: 0.091497\n",
            "Iteration: 41 \t Training Loss: 0.091189\n",
            "*--------*\n",
            "Epoch: 4 \t Training Loss: 0.091163\n",
            "Epoch: 4 \t Validation loss: 0.10, p: 0.85, r: 0.11, f1: 0.19\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.094442\n",
            "Iteration: 11 \t Training Loss: 0.089356\n",
            "Iteration: 21 \t Training Loss: 0.090359\n",
            "Iteration: 31 \t Training Loss: 0.090189\n",
            "Iteration: 41 \t Training Loss: 0.091182\n",
            "*--------*\n",
            "Epoch: 5 \t Training Loss: 0.091305\n",
            "Epoch: 5 \t Validation loss: 0.10, p: 0.75, r: 0.15, f1: 0.25\n",
            "trigger times: 1\n",
            "Iteration: 1 \t Training Loss: 0.093705\n",
            "Iteration: 11 \t Training Loss: 0.089946\n",
            "Iteration: 21 \t Training Loss: 0.089451\n",
            "Iteration: 31 \t Training Loss: 0.091172\n",
            "Iteration: 41 \t Training Loss: 0.091429\n",
            "*--------*\n",
            "Epoch: 6 \t Training Loss: 0.091260\n",
            "Epoch: 6 \t Validation loss: 0.10, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 2\n",
            "Iteration: 1 \t Training Loss: 0.090395\n",
            "Iteration: 11 \t Training Loss: 0.090720\n",
            "Iteration: 21 \t Training Loss: 0.090569\n",
            "Iteration: 31 \t Training Loss: 0.091281\n",
            "Iteration: 41 \t Training Loss: 0.091402\n",
            "*--------*\n",
            "Epoch: 7 \t Training Loss: 0.091465\n",
            "Epoch: 7 \t Validation loss: 0.10, p: 0.85, r: 0.11, f1: 0.19\n",
            "trigger times: 3\n",
            "Iteration: 1 \t Training Loss: 0.089393\n",
            "Iteration: 11 \t Training Loss: 0.089860\n",
            "Iteration: 21 \t Training Loss: 0.091931\n",
            "Iteration: 31 \t Training Loss: 0.091349\n",
            "Iteration: 41 \t Training Loss: 0.091313\n",
            "*--------*\n",
            "Epoch: 8 \t Training Loss: 0.091445\n",
            "Epoch: 8 \t Validation loss: 0.10, p: 0.75, r: 0.15, f1: 0.25\n",
            "trigger times: 4\n",
            "Early stopping!\n",
            "Start to test process.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (embedding): Embedding(10932, 300)\n",
              "  (conv): Conv1d(300, 3, kernel_size=(250,), stride=(1,))\n",
              "  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc_layers): ModuleList(\n",
              "    (0): Linear(in_features=2914, out_features=3000, bias=True)\n",
              "    (1): Sigmoid()\n",
              "    (2): Linear(in_features=3000, out_features=500, bias=True)\n",
              "    (3): Sigmoid()\n",
              "  )\n",
              "  (fc_final): Linear(in_features=500, out_features=649, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "train(cnn_model_cat_2, train_dataloader, val_dataloader, nEpochs, cnn_optimizer_cat_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc237bf7",
      "metadata": {
        "id": "bc237bf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38cbfc4b-ca6d-4f19-8dc3-7a27af9242d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.09837424222912107,\n",
              " 0.7139240506329114,\n",
              " 0.15398038464215916,\n",
              " 0.24977509499161732)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "eval_model(cnn_model_cat_2, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "556ef1dc",
      "metadata": {
        "id": "556ef1dc"
      },
      "source": [
        "### CNN Baseline w/ Cat 3 Dense "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18e00efb",
      "metadata": {
        "id": "18e00efb"
      },
      "outputs": [],
      "source": [
        "cnn_model_cat_3 = CNNModel(vocabSize+1, numCodes, len(uniqueCats), 3, [3000, 700, 200])\n",
        "cnn_optimizer_cat_3 = torch.optim.Adam(cnn_model_cat_3.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d5fa958",
      "metadata": {
        "id": "9d5fa958",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7432d6bc-a7bf-4150-ab6d-cb95999a4f99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1 \t Training Loss: 0.702221\n",
            "Iteration: 11 \t Training Loss: 0.451103\n",
            "Iteration: 21 \t Training Loss: 0.305266\n",
            "Iteration: 31 \t Training Loss: 0.239177\n",
            "Iteration: 41 \t Training Loss: 0.204168\n",
            "*--------*\n",
            "Epoch: 1 \t Training Loss: 0.183494\n",
            "Epoch: 1 \t Validation loss: 0.09, p: 0.85, r: 0.11, f1: 0.19\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.087790\n",
            "Iteration: 11 \t Training Loss: 0.090504\n",
            "Iteration: 21 \t Training Loss: 0.090300\n",
            "Iteration: 31 \t Training Loss: 0.091197\n",
            "Iteration: 41 \t Training Loss: 0.091375\n",
            "*--------*\n",
            "Epoch: 2 \t Training Loss: 0.091435\n",
            "Epoch: 2 \t Validation loss: 0.09, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 1\n",
            "Iteration: 1 \t Training Loss: 0.085054\n",
            "Iteration: 11 \t Training Loss: 0.089327\n",
            "Iteration: 21 \t Training Loss: 0.089370\n",
            "Iteration: 31 \t Training Loss: 0.090536\n",
            "Iteration: 41 \t Training Loss: 0.090760\n",
            "*--------*\n",
            "Epoch: 3 \t Training Loss: 0.091121\n",
            "Epoch: 3 \t Validation loss: 0.09, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 2\n",
            "Iteration: 1 \t Training Loss: 0.096451\n",
            "Iteration: 11 \t Training Loss: 0.091520\n",
            "Iteration: 21 \t Training Loss: 0.091167\n",
            "Iteration: 31 \t Training Loss: 0.091069\n",
            "Iteration: 41 \t Training Loss: 0.091016\n",
            "*--------*\n",
            "Epoch: 4 \t Training Loss: 0.091055\n",
            "Epoch: 4 \t Validation loss: 0.09, p: 0.71, r: 0.10, f1: 0.17\n",
            "trigger times: 3\n",
            "Iteration: 1 \t Training Loss: 0.090030\n",
            "Iteration: 11 \t Training Loss: 0.089798\n",
            "Iteration: 21 \t Training Loss: 0.091167\n",
            "Iteration: 31 \t Training Loss: 0.090781\n",
            "Iteration: 41 \t Training Loss: 0.090953\n",
            "*--------*\n",
            "Epoch: 5 \t Training Loss: 0.090945\n",
            "Epoch: 5 \t Validation loss: 0.09, p: 0.85, r: 0.11, f1: 0.19\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.091867\n",
            "Iteration: 11 \t Training Loss: 0.091284\n",
            "Iteration: 21 \t Training Loss: 0.090652\n",
            "Iteration: 31 \t Training Loss: 0.090581\n",
            "Iteration: 41 \t Training Loss: 0.090769\n",
            "*--------*\n",
            "Epoch: 6 \t Training Loss: 0.090879\n",
            "Epoch: 6 \t Validation loss: 0.10, p: 0.71, r: 0.10, f1: 0.17\n",
            "trigger times: 1\n",
            "Iteration: 1 \t Training Loss: 0.090509\n",
            "Iteration: 11 \t Training Loss: 0.090765\n",
            "Iteration: 21 \t Training Loss: 0.090659\n",
            "Iteration: 31 \t Training Loss: 0.090919\n",
            "Iteration: 41 \t Training Loss: 0.090802\n",
            "*--------*\n",
            "Epoch: 7 \t Training Loss: 0.091060\n",
            "Epoch: 7 \t Validation loss: 0.10, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.098818\n",
            "Iteration: 11 \t Training Loss: 0.092215\n",
            "Iteration: 21 \t Training Loss: 0.091590\n",
            "Iteration: 31 \t Training Loss: 0.091263\n",
            "Iteration: 41 \t Training Loss: 0.091563\n",
            "*--------*\n",
            "Epoch: 8 \t Training Loss: 0.091024\n",
            "Epoch: 8 \t Validation loss: 0.10, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 1\n",
            "Iteration: 1 \t Training Loss: 0.088035\n",
            "Iteration: 11 \t Training Loss: 0.089048\n",
            "Iteration: 21 \t Training Loss: 0.089889\n",
            "Iteration: 31 \t Training Loss: 0.090829\n",
            "Iteration: 41 \t Training Loss: 0.090858\n",
            "*--------*\n",
            "Epoch: 9 \t Training Loss: 0.091009\n",
            "Epoch: 9 \t Validation loss: 0.10, p: 0.85, r: 0.11, f1: 0.19\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.090863\n",
            "Iteration: 11 \t Training Loss: 0.091040\n",
            "Iteration: 21 \t Training Loss: 0.090994\n",
            "Iteration: 31 \t Training Loss: 0.091157\n",
            "Iteration: 41 \t Training Loss: 0.090573\n",
            "*--------*\n",
            "Epoch: 10 \t Training Loss: 0.091045\n",
            "Epoch: 10 \t Validation loss: 0.10, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 1\n",
            "Iteration: 1 \t Training Loss: 0.086935\n",
            "Iteration: 11 \t Training Loss: 0.094743\n",
            "Iteration: 21 \t Training Loss: 0.092546\n",
            "Iteration: 31 \t Training Loss: 0.092026\n",
            "Iteration: 41 \t Training Loss: 0.091026\n",
            "*--------*\n",
            "Epoch: 11 \t Training Loss: 0.090970\n",
            "Epoch: 11 \t Validation loss: 0.10, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 2\n",
            "Iteration: 1 \t Training Loss: 0.089538\n",
            "Iteration: 11 \t Training Loss: 0.091999\n",
            "Iteration: 21 \t Training Loss: 0.090680\n",
            "Iteration: 31 \t Training Loss: 0.091175\n",
            "Iteration: 41 \t Training Loss: 0.090595\n",
            "*--------*\n",
            "Epoch: 12 \t Training Loss: 0.091117\n",
            "Epoch: 12 \t Validation loss: 0.10, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 3\n",
            "Iteration: 1 \t Training Loss: 0.095294\n",
            "Iteration: 11 \t Training Loss: 0.091411\n",
            "Iteration: 21 \t Training Loss: 0.092583\n",
            "Iteration: 31 \t Training Loss: 0.092111\n",
            "Iteration: 41 \t Training Loss: 0.090920\n",
            "*--------*\n",
            "Epoch: 13 \t Training Loss: 0.091131\n",
            "Epoch: 13 \t Validation loss: 0.10, p: 0.71, r: 0.10, f1: 0.17\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.089422\n",
            "Iteration: 11 \t Training Loss: 0.092392\n",
            "Iteration: 21 \t Training Loss: 0.091899\n",
            "Iteration: 31 \t Training Loss: 0.091951\n",
            "Iteration: 41 \t Training Loss: 0.091062\n",
            "*--------*\n",
            "Epoch: 14 \t Training Loss: 0.091171\n",
            "Epoch: 14 \t Validation loss: 0.10, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 1\n",
            "Iteration: 1 \t Training Loss: 0.088116\n",
            "Iteration: 11 \t Training Loss: 0.092843\n",
            "Iteration: 21 \t Training Loss: 0.092416\n",
            "Iteration: 31 \t Training Loss: 0.092591\n",
            "Iteration: 41 \t Training Loss: 0.091632\n",
            "*--------*\n",
            "Epoch: 15 \t Training Loss: 0.091132\n",
            "Epoch: 15 \t Validation loss: 0.10, p: 0.86, r: 0.06, f1: 0.11\n",
            "trigger times: 0\n"
          ]
        }
      ],
      "source": [
        "train(cnn_model_cat_3, train_dataloader, val_dataloader, nEpochs, cnn_optimizer_cat_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef822eaf",
      "metadata": {
        "id": "ef822eaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1581da2-d606-4b49-a60b-bbe06f4602ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.1038111224770546,\n",
              " 0.569620253164557,\n",
              " 0.04238887639120817,\n",
              " 0.07824123362627106)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "eval_model(cnn_model_cat_3, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN 3-Conv1D"
      ],
      "metadata": {
        "id": "2l3Sh7O30BDu"
      },
      "id": "2l3Sh7O30BDu"
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN3ConvModel(nn.Module):    \n",
        "    def __init__(self, num_words, out_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings=num_words, embedding_dim=300)\n",
        "        self.conv1 = nn.Conv1d(300, 2, 250)\n",
        "        self.conv2 = nn.Conv1d(300, 3, 250)\n",
        "        self.conv3 = nn.Conv1d(300, 4, 250)\n",
        "        self.maxpool = nn.MaxPool1d(3, 2)\n",
        "        prev_size = (3*(((max_report_len-251)//2)+1)) + (3*(((max_report_len-252)//2)+1)) + (3*(((max_report_len-253)//2)+1)) -3\n",
        "        self.fc_final = nn.Linear(in_features=prev_size, out_features=out_classes)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x, mask, cat):\n",
        "        x = self.embedding(x)\n",
        "        maskUnsq = mask.unsqueeze(-1)\n",
        "        x = x*maskUnsq    # 32 x max_size x 300\n",
        "        x = torch.permute(x, (0, 2, 1)) # 32 x 300 x max_size\n",
        "\n",
        "        x1 = F.relu(self.conv1(x)) # 32 x 250 x (max_size-1)\n",
        "        x1 = self.maxpool(x1)   # 32 x 250 x ((max_size-4)//2)+1\n",
        "\n",
        "        x2 = F.relu(self.conv2(x)) # 32 x 250 x (max_size-2)\n",
        "        x2 = self.maxpool(x2)   # 32 x 250 x ((max_size-5)//2)+1\n",
        "\n",
        "        x3 = F.relu(self.conv3(x)) # 32 x 250 x (max_size-3)\n",
        "        x3 = self.maxpool(x3)   # 32 x 250 x ((max_size-6)//2)+1\n",
        "  \n",
        "        x1 = torch.flatten(x1, 1, -1) # 32 x (250*(((max_size-4)//2)+1))\n",
        "        x2 = torch.flatten(x2, 1, -1) # 32 x (250*(((max_size-5)//2)+1))\n",
        "        x3 = torch.flatten(x3, 1, -1) # 32 x (250*(((max_size-6)//2)+1))\n",
        "\n",
        "        x = torch.cat((x1, x2, x3), dim=-1)\n",
        "        x = self.fc_final(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "7tHjaGFD0JZe"
      },
      "id": "7tHjaGFD0JZe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn3_model = CNN3ConvModel(vocabSize+1, numCodes)\n",
        "cnn3_optimizer = torch.optim.Adam(cnn3_model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "60q6vIo5Sx9B"
      },
      "id": "60q6vIo5Sx9B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(cnn3_model, train_dataloader, val_dataloader, nEpochs, cnn3_optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAA7Z9s1TE-p",
        "outputId": "6ff4d64e-5a20-4de1-8f4d-9db6e5516880"
      },
      "id": "VAA7Z9s1TE-p",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1 \t Training Loss: 0.695636\n",
            "Iteration: 11 \t Training Loss: 0.399785\n",
            "Iteration: 21 \t Training Loss: 0.324538\n",
            "Iteration: 31 \t Training Loss: 0.268383\n",
            "Iteration: 41 \t Training Loss: 0.228748\n",
            "*--------*\n",
            "Epoch: 1 \t Training Loss: 0.204987\n",
            "Epoch: 1 \t Validation loss: 0.10, p: 0.77, r: 0.08, f1: 0.14\n",
            "trigger times: 0\n",
            "Iteration: 1 \t Training Loss: 0.096259\n",
            "Iteration: 11 \t Training Loss: 0.091312\n",
            "Iteration: 21 \t Training Loss: 0.089393\n",
            "Iteration: 31 \t Training Loss: 0.088944\n",
            "Iteration: 41 \t Training Loss: 0.088103\n",
            "*--------*\n",
            "Epoch: 2 \t Training Loss: 0.087731\n",
            "Epoch: 2 \t Validation loss: 0.10, p: 0.75, r: 0.09, f1: 0.16\n",
            "trigger times: 1\n",
            "Iteration: 1 \t Training Loss: 0.079027\n",
            "Iteration: 11 \t Training Loss: 0.078640\n",
            "Iteration: 21 \t Training Loss: 0.077874\n",
            "Iteration: 31 \t Training Loss: 0.077287\n",
            "Iteration: 41 \t Training Loss: 0.077694\n",
            "*--------*\n",
            "Epoch: 3 \t Training Loss: 0.077339\n",
            "Epoch: 3 \t Validation loss: 0.12, p: 0.67, r: 0.11, f1: 0.18\n",
            "trigger times: 2\n",
            "Iteration: 1 \t Training Loss: 0.073447\n",
            "Iteration: 11 \t Training Loss: 0.065896\n",
            "Iteration: 21 \t Training Loss: 0.066301\n",
            "Iteration: 31 \t Training Loss: 0.065288\n",
            "Iteration: 41 \t Training Loss: 0.065270\n",
            "*--------*\n",
            "Epoch: 4 \t Training Loss: 0.064888\n",
            "Epoch: 4 \t Validation loss: 0.13, p: 0.61, r: 0.11, f1: 0.18\n",
            "trigger times: 3\n",
            "Iteration: 1 \t Training Loss: 0.059246\n",
            "Iteration: 11 \t Training Loss: 0.051969\n",
            "Iteration: 21 \t Training Loss: 0.051219\n",
            "Iteration: 31 \t Training Loss: 0.050829\n",
            "Iteration: 41 \t Training Loss: 0.050431\n",
            "*--------*\n",
            "Epoch: 5 \t Training Loss: 0.050578\n",
            "Epoch: 5 \t Validation loss: 0.15, p: 0.58, r: 0.11, f1: 0.18\n",
            "trigger times: 4\n",
            "Early stopping!\n",
            "Start to test process.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN3ConvModel(\n",
              "  (embedding): Embedding(10932, 300)\n",
              "  (conv1): Conv1d(300, 2, kernel_size=(250,), stride=(1,))\n",
              "  (conv2): Conv1d(300, 3, kernel_size=(250,), stride=(1,))\n",
              "  (conv3): Conv1d(300, 4, kernel_size=(250,), stride=(1,))\n",
              "  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc_final): Linear(in_features=8703, out_features=649, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(cnn3_model, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REGi0QVCTPC6",
        "outputId": "b8fbc9bb-1814-4824-aae4-8fb90de911c6"
      },
      "id": "REGi0QVCTPC6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.1336854887860162,\n",
              " 0.5238137336313062,\n",
              " 0.10876606049522144,\n",
              " 0.1696703450825693)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BqMSncSfTdNl"
      },
      "id": "BqMSncSfTdNl",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "baselines",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}